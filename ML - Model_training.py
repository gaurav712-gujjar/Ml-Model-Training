# -*- coding: utf-8 -*-
"""practice_data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kYfVXI-GgfD3bQYm5d9x4KuHkcarTltB
"""

#load data -- check null value -- categorial to numerical --
#train_test_split -- min_max_scaler

import pandas as pd
import sklearn
import seaborn as sns
import numpy as np

df = pd.read_csv("/content/Churn_Modelling - Churn_Modelling.csv")

df.head()

df.drop(['Surname','Geography'], axis=1, inplace=True)

from sklearn.preprocessing import LabelEncoder

lb = LabelEncoder()

df['Gender']=lb.fit_transform(df['Gender'])

df.head()

df.isnull().sum()

from sklearn.model_selection import train_test_split

x=df.drop(columns=['Exited'])
y=df['Exited']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=65)

print("Total shape of df :", df.shape)
print('-------------------------------')
print("independent data shape :", x.shape)
print("x_train data shape :", x_train.shape)
print("x_test data shape :",x_test.shape)
print("--------------------------------")
print("Target data shape :", y.shape)
print("y_train data shape :",y_train.shape)
print("y_test data shape :",y_test.shape)

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

b = sc.fit_transform(x_train)

data = pd.DataFrame(b, columns = x_train.columns)

np.round(data.describe(),2)

from sklearn.preprocessing import MinMaxScaler

a = MinMaxScaler()

b = a.fit_transform(x_train)

frame = pd.DataFrame(b, columns = x_train.columns )

np.round(frame.describe(),2)

